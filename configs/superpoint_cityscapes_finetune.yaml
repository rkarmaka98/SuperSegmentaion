# Configuration for training SuperPoint on the Cityscapes dataset
# Segmentation labels can be reduced to 4 coarse categories

data:
    dataset: 'Cityscapes'
    root: 'datasets/Cityscapes'  # path to Cityscapes images
    labels: logs/magicpoint_synth_homoAdapt_cityscape/predictions
    segmentation_labels: 'datasets/Cityscapes/gtFine'  # segmentation masks
    grayscale: true               # use single-channel grayscale images
    cache_in_memory: false
    load_segmentation: true
    reduce_to_4_categories: true
    debug_dump: false
    num_segmentation_classes: 4
    gaussian_label:
        enable: true
        params:
            GaussianBlur: {sigma: 0.2}
    preprocessing:
        resize: [256, 512]  # images are downsampled for training
    augmentation:
        photometric:
            enable: true
            primitives: [
                'random_brightness', 'random_contrast', 'additive_speckle_noise',
                'additive_gaussian_noise', 'additive_shade', 'motion_blur']
            params:
                random_brightness: {max_abs_change: 30}
                random_contrast: {strength_range: [0.8, 1.2]}
                additive_gaussian_noise: {stddev_range: [0, 10]}
                additive_speckle_noise: {prob_range: [0, 0.0035]}
                additive_shade:
                    transparency_range: [-0.5, 0.5]
                    kernel_size_range: [100, 150]
                motion_blur: {max_kernel_size: 3}
        homographic:
            enable: false
    warped_pair:
        enable: true
        params:
            translation: true
            rotation: true
            scaling: true
            perspective: true
            yaw_range: 2.0
            pitch_range: 2.0
            roll_range: 2.0
            patch_ratio: 0.85  # wider valid area
            max_angle: 1.0  # ~57 degrees
            allow_artifacts: true
        valid_border_margin: 10

front_end_model: 'Train_model_heatmap'  # use heatmap detector
training:
    workers_train: 8
    workers_val: 8
    workers_test: 8

model:
    name: 'SuperPointNet_gauss2'
    # use single-channel inputs when training on grayscale images
    params:
        input_channels: 1
    detector_loss:
        loss_type: 'softmax'

    batch_size: 4
    eval_batch_size: 4
    learning_rate: 0.0001  # reasonable learning rate
    detection_threshold: 0.015
    lambda_loss: 1
    lambda_segmentation: 1.0
    num_segmentation_classes: 4
    compute_miou: true  # log mIoU for each batch
    nms: 4
    dense_loss:
        enable: false

    sparse_loss:
        enable: true
        params:
            num_matching_attempts: 1000
            num_masked_non_matches_per_match: 100
            lamda_d: 1
            dist: 'cos'
            method: '2d'
    other_settings: 'finetune 2d, gauss 0.2'

retrain: True
reset_iter: True
train_iter: 100 #170000
validation_interval: 25 #2000
tensorboard_interval: 25
save_interval: 25 #2000
validation_size: 5
truncate: 100

pretrained: 'logs/superpoint_coco/checkpoints/superPointNet_200_checkpoint.pth.tar'
    # pretrained: 'logs/superpoint_coco_heat2_0/checkpoints/superPointNet_90000_checkpoint.pth.tar'

